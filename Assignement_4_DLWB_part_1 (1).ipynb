{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f946675-c8d9-452f-b409-db00d127517f",
   "metadata": {},
   "source": [
    "## part 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d140a449-0108-4c6e-89e3-fcbc7cecac90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5be77e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7667b069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff0cec5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_11509/711152576.py:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting official/mnist/dataset/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting official/mnist/dataset/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting official/mnist/dataset/t10k-images-idx3-ubyte.gz\n",
      "Extracting official/mnist/dataset/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"official/mnist/dataset/\", one_hot=True)\n",
    "                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cbf56c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.contrib.learn.python.learn.datasets.base.Datasets"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71ef8bc8-3fc6-41c4-846e-a77c626fd003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a777de77-38fd-4f57-8f64-3a5692c7aec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131b6359-4016-429d-ab55-544786c51b3c",
   "metadata": {},
   "source": [
    "## Preperation for Building CNN Model: Define Supporting Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b14a1f-fe86-4383-af80-974d974e7eae",
   "metadata": {},
   "source": [
    "### Initialize Weights in Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f663fcc0-4a8c-4330-a3bf-25c436d3e15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intialize_weights (filter_shape):\n",
    "    init_random_dist = tf.random.truncated_normal(filter_shape, stddev=0.1)\n",
    "    return ( tf.Variable(init_random_dist) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a04ccf-9a24-4f4a-b65a-812580fd17b8",
   "metadata": {},
   "source": [
    "### Initialize bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52170b43-3cb7-421d-a12e-551484237f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_bias(bias_shape):\n",
    "    init_bias_vals = tf.constant(0.1, shape=bias_shape)\n",
    "    return tf.Variable(init_bias_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500dc542-2afd-4c92-9634-02e2e820e99a",
   "metadata": {},
   "source": [
    "### Set Up Convolutional Layer and Perform Convulution: Dot Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "961da263-cc53-437f-9d80-f2d813b0aac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_convolution_layer_and_compute_dot_product(inputs, filter_shape):\n",
    "    filter_initialized_with_weights = intialize_weights(filter_shape)\n",
    "    conv_layer_outputs = tf.nn.conv2d(inputs, filter_initialized_with_weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    return (conv_layer_outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f90ac01-ee10-415a-9da4-4d17e5a3af40",
   "metadata": {},
   "source": [
    "### Set Up Convolutional Layer and Perform Convukution: Dot Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "072732b8-d4ca-4e67-9940-246285fc4682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_relu_layer_and_compute_dotproduct_plus_b(inputs, filter_shape):\n",
    "    b = initialize_bias ([filter_shape[3]])\n",
    "    relu_layer_outputs = tf.nn.relu(inputs +b)\n",
    "    return(relu_layer_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baa0098-b295-4155-aaa8-cfb2f4a3fce1",
   "metadata": {},
   "source": [
    "### Set Up Pooling Layer and Reduce Spatial Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ae472e0-1ae2-4405-9215-7916ba41314b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_maxpool2by2_and_reduce_spatial_size(inputs):\n",
    "    pooling_layer_outputs = tf.nn.max_pool2d(inputs, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    return pooling_layer_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5e5ea3-e86c-4052-bbfb-a0f923a9430d",
   "metadata": {},
   "source": [
    "### Set Up Fully Connected Layer and Perform Computation: (inputs*Weights)+ Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc0c8e7f-57bb-4bf6-ae91-01ea70ba168d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fully_connected_layer_and_compute_dotproduct_plus_bias (inputs, output_size):\n",
    "    input_size = int(inputs.get_shape()[1])\n",
    "    W = intialize_weights ([input_size, output_size])\n",
    "    b = initialize_bias ([output_size])\n",
    "    fc_xW_plus_bias_outputs = tf.matmul(inputs, W) +b\n",
    "    return (fc_xW_plus_bias_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db64bff-c946-4d2e-a93c-f39aae00f603",
   "metadata": {},
   "source": [
    "## Pahse 1: Build The Convolution Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cce703-9803-4df6-a8b5-cb3c580d8dde",
   "metadata": {},
   "source": [
    "### Create Placeholder for inputs and Labels: x&y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51fbbf35-9ad1-4a7f-b596-247af0a8ed5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.compat.v1.placeholder(tf.float32, shape=[None, 784])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98b77808-5643-4006-bc5c-442f1277d9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.compat.v1.placeholder(tf.float32,[None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1dbc7f-fc05-4903-92db-9ef9c6f33ae2",
   "metadata": {},
   "source": [
    "### Reshape the input placeholder x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ebd8f72-f206-4026-b0fa-3b21f8466a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1,28,28,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c63f18c-d489-44a4-b7d1-1bd106fdfb4d",
   "metadata": {},
   "source": [
    "### Create 1st Convolution Layer, ReLU layer and perform Computation: x*W+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74d72cc6-1b66-46c8-b577-d8310d3316de",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_1_outputs \\\n",
    "    = create_convolution_layer_and_compute_dot_product (x_image, filter_shape=[5,5,1,32])\n",
    "conv_relu_layer_1_outputs \\\n",
    "    = create_relu_layer_and_compute_dotproduct_plus_b (conv_layer_1_outputs, filter_shape=[5,5,1,32])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0bd0e5-83da-4473-8885-71aa4580b378",
   "metadata": {},
   "source": [
    "### Create 1st Pooling Layer and Reduce Spatial Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05342963-abf4-46ff-ad7e-77a133e8d994",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooling_layer_1_outputs = create_maxpool2by2_and_reduce_spatial_size(conv_relu_layer_1_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf7b3d1-af2a-4acd-95cd-930bdd8bef59",
   "metadata": {},
   "source": [
    "### Create 2nd Convolutional layer, ReLU Layer and Perform Computation: x*W+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c5b7060-7b41-4efb-9629-b3af76c85597",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_2_outputs \\\n",
    "    = create_convolution_layer_and_compute_dot_product (pooling_layer_1_outputs, filter_shape=[5,5,32,64])\n",
    "conv_relu_layer_2_outputs \\\n",
    "    = create_relu_layer_and_compute_dotproduct_plus_b (conv_layer_2_outputs, filter_shape=[5,5,32,64])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf04e81-0893-4eb7-bee8-d4319693144d",
   "metadata": {},
   "source": [
    "### Create 2nd Pooling Layer and Reduce Spatial Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "575a4903-eeac-4b43-a404-9a3177101296",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooling_layer_2_outputs = create_maxpool2by2_and_reduce_spatial_size(conv_relu_layer_2_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743d0c8b-9fb9-4391-9323-8d01b62229b5",
   "metadata": {},
   "source": [
    "### Reshape/Flatten Data Making it Ready to be Fed inti 1st FC Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3e5ce82-bccf-4ab6-82c0-58f6a3f0a5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooling_layer_2_outputs_flat = tf.reshape(pooling_layer_2_outputs, [-1,7*7*64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4da5f3bd-a05e-4d70-900e-b2aefa59b4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_layer_1_outputs \\\n",
    "    = create_fully_connected_layer_and_compute_dotproduct_plus_bias(pooling_layer_2_outputs_flat, output_size=1024)\n",
    "fc_relu_layer_1_outputs = tf.nn.relu(fc_layer_1_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "edc58e28-c210-4783-a871-17b29a23701d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_prob = tf.compat.v1.placeholder(tf.float32)\n",
    "rate = 1 - hold_prob\n",
    "fc_dropout_outputs = tf.nn.dropout(fc_relu_layer_1_outputs, rate=rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3995907f-4cd3-453e-ba00-a92d2d64cab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = create_fully_connected_layer_and_compute_dotproduct_plus_bias(fc_dropout_outputs, output_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9640895e-f03c-4d60-83ba-2899a06a2851",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_cross_entropy_loss = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_true, logits=y_pred)\n",
    "cross_entropy_mean = tf.reduce_mean (softmax_cross_entropy_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b66e72db-1ba4-43b6-b26e-ab8b38e4734d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.compat.v1.train.AdamOptimizer (learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "170178d2-ad38-4a30-b7be-4b5eee79b3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_trainer = optimizer.minimize(cross_entropy_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ffb7ac7-4172-4965-b091-bb3edb64d346",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_initializer = tf.compat.v1.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5784fcb5-2d9e-40df-a07c-9e3a74bdf5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf88ef1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.\n",
      "OMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info\n",
      "OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-7\n",
      "OMP: Info #156: KMP_AFFINITY: 8 available OS procs\n",
      "OMP: Info #157: KMP_AFFINITY: Uniform topology\n",
      "OMP: Info #179: KMP_AFFINITY: 1 packages x 4 cores/pkg x 2 threads/core (4 total cores)\n",
      "OMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:\n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 4 maps to package 0 core 0 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 core 1 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 5 maps to package 0 core 1 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 2 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 6 maps to package 0 core 2 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 0 core 3 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 7 maps to package 0 core 3 thread 1 \n",
      "OMP: Info #250: KMP_AFFINITY: pid 11509 tid 11553 thread 0 bound to OS proc set 0\n",
      "OMP: Info #250: KMP_AFFINITY: pid 11509 tid 11553 thread 1 bound to OS proc set 1\n",
      "OMP: Info #250: KMP_AFFINITY: pid 11509 tid 11607 thread 2 bound to OS proc set 2\n",
      "OMP: Info #250: KMP_AFFINITY: pid 11509 tid 11608 thread 3 bound to OS proc set 3\n",
      "OMP: Info #250: KMP_AFFINITY: pid 11509 tid 11609 thread 4 bound to OS proc set 4\n",
      "OMP: Info #250: KMP_AFFINITY: pid 11509 tid 11610 thread 5 bound to OS proc set 5\n",
      "OMP: Info #250: KMP_AFFINITY: pid 11509 tid 11611 thread 6 bound to OS proc set 6\n",
      "OMP: Info #250: KMP_AFFINITY: pid 11509 tid 11612 thread 7 bound to OS proc set 7\n",
      "OMP: Info #250: KMP_AFFINITY: pid 11509 tid 11613 thread 8 bound to OS proc set 0\n",
      "OMP: Info #250: KMP_AFFINITY: pid 11509 tid 11554 thread 9 bound to OS proc set 1\n",
      "OMP: Info #250: KMP_AFFINITY: pid 11509 tid 11614 thread 10 bound to OS proc set 2\n",
      "OMP: Info #250: KMP_AFFINITY: pid 11509 tid 11615 thread 11 bound to OS proc set 3\n",
      "OMP: Info #250: KMP_AFFINITY: pid 11509 tid 11616 thread 12 bound to OS proc set 4\n",
      "OMP: Info #250: KMP_AFFINITY: pid 11509 tid 11617 thread 13 bound to OS proc set 5\n",
      "OMP: Info #250: KMP_AFFINITY: pid 11509 tid 11618 thread 14 bound to OS proc set 6\n",
      "OMP: Info #250: KMP_AFFINITY: pid 11509 tid 11619 thread 15 bound to OS proc set 7\n",
      "OMP: Info #250: KMP_AFFINITY: pid 11509 tid 11620 thread 16 bound to OS proc set 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ON STEP :0\n",
      "ACCURACY: \n",
      "0.1662\n",
      "\n",
      "\n",
      "ON STEP :100\n",
      "ACCURACY: \n",
      "0.9402\n",
      "\n",
      "\n",
      "ON STEP :200\n",
      "ACCURACY: \n",
      "0.9614\n",
      "\n",
      "\n",
      "ON STEP :300\n",
      "ACCURACY: \n",
      "0.9681\n",
      "\n",
      "\n",
      "ON STEP :400\n",
      "ACCURACY: \n",
      "0.9726\n",
      "\n",
      "\n",
      "ON STEP :500\n",
      "ACCURACY: \n",
      "0.9768\n",
      "\n",
      "\n",
      "ON STEP :600\n",
      "ACCURACY: \n",
      "0.9786\n",
      "\n",
      "\n",
      "ON STEP :700\n",
      "ACCURACY: \n",
      "0.977\n",
      "\n",
      "\n",
      "ON STEP :800\n",
      "ACCURACY: \n",
      "0.9791\n",
      "\n",
      "\n",
      "ON STEP :900\n",
      "ACCURACY: \n",
      "0.9791\n",
      "\n",
      "\n",
      "ON STEP :1000\n",
      "ACCURACY: \n",
      "0.9837\n",
      "\n",
      "\n",
      "ON STEP :1100\n",
      "ACCURACY: \n",
      "0.9831\n",
      "\n",
      "\n",
      "ON STEP :1200\n",
      "ACCURACY: \n",
      "0.9849\n",
      "\n",
      "\n",
      "ON STEP :1300\n",
      "ACCURACY: \n",
      "0.9841\n",
      "\n",
      "\n",
      "ON STEP :1400\n",
      "ACCURACY: \n",
      "0.9851\n",
      "\n",
      "\n",
      "ON STEP :1500\n",
      "ACCURACY: \n",
      "0.9859\n",
      "\n",
      "\n",
      "ON STEP :1600\n",
      "ACCURACY: \n",
      "0.9846\n",
      "\n",
      "\n",
      "ON STEP :1700\n",
      "ACCURACY: \n",
      "0.983\n",
      "\n",
      "\n",
      "ON STEP :1800\n",
      "ACCURACY: \n",
      "0.9849\n",
      "\n",
      "\n",
      "ON STEP :1900\n",
      "ACCURACY: \n",
      "0.9868\n",
      "\n",
      "\n",
      "ON STEP :2000\n",
      "ACCURACY: \n",
      "0.984\n",
      "\n",
      "\n",
      "ON STEP :2100\n",
      "ACCURACY: \n",
      "0.9866\n",
      "\n",
      "\n",
      "ON STEP :2200\n",
      "ACCURACY: \n",
      "0.9872\n",
      "\n",
      "\n",
      "ON STEP :2300\n",
      "ACCURACY: \n",
      "0.9886\n",
      "\n",
      "\n",
      "ON STEP :2400\n",
      "ACCURACY: \n",
      "0.9865\n",
      "\n",
      "\n",
      "ON STEP :2500\n",
      "ACCURACY: \n",
      "0.9885\n",
      "\n",
      "\n",
      "ON STEP :2600\n",
      "ACCURACY: \n",
      "0.9865\n",
      "\n",
      "\n",
      "ON STEP :2700\n",
      "ACCURACY: \n",
      "0.9862\n",
      "\n",
      "\n",
      "ON STEP :2800\n",
      "ACCURACY: \n",
      "0.9875\n",
      "\n",
      "\n",
      "ON STEP :2900\n",
      "ACCURACY: \n",
      "0.9853\n",
      "\n",
      "\n",
      "ON STEP :3000\n",
      "ACCURACY: \n",
      "0.9888\n",
      "\n",
      "\n",
      "ON STEP :3100\n",
      "ACCURACY: \n",
      "0.9896\n",
      "\n",
      "\n",
      "ON STEP :3200\n",
      "ACCURACY: \n",
      "0.9888\n",
      "\n",
      "\n",
      "ON STEP :3300\n",
      "ACCURACY: \n",
      "0.9893\n",
      "\n",
      "\n",
      "ON STEP :3400\n",
      "ACCURACY: \n",
      "0.9887\n",
      "\n",
      "\n",
      "ON STEP :3500\n",
      "ACCURACY: \n",
      "0.989\n",
      "\n",
      "\n",
      "ON STEP :3600\n",
      "ACCURACY: \n",
      "0.9893\n",
      "\n",
      "\n",
      "ON STEP :3700\n",
      "ACCURACY: \n",
      "0.9908\n",
      "\n",
      "\n",
      "ON STEP :3800\n",
      "ACCURACY: \n",
      "0.9892\n",
      "\n",
      "\n",
      "ON STEP :3900\n",
      "ACCURACY: \n",
      "0.9882\n",
      "\n",
      "\n",
      "ON STEP :4000\n",
      "ACCURACY: \n",
      "0.9867\n",
      "\n",
      "\n",
      "ON STEP :4100\n",
      "ACCURACY: \n",
      "0.9898\n",
      "\n",
      "\n",
      "ON STEP :4200\n",
      "ACCURACY: \n",
      "0.9888\n",
      "\n",
      "\n",
      "ON STEP :4300\n",
      "ACCURACY: \n",
      "0.9895\n",
      "\n",
      "\n",
      "ON STEP :4400\n",
      "ACCURACY: \n",
      "0.9902\n",
      "\n",
      "\n",
      "ON STEP :4500\n",
      "ACCURACY: \n",
      "0.9898\n",
      "\n",
      "\n",
      "ON STEP :4600\n",
      "ACCURACY: \n",
      "0.9904\n",
      "\n",
      "\n",
      "ON STEP :4700\n",
      "ACCURACY: \n",
      "0.9885\n",
      "\n",
      "\n",
      "ON STEP :4800\n",
      "ACCURACY: \n",
      "0.9877\n",
      "\n",
      "\n",
      "ON STEP :4900\n",
      "ACCURACY: \n",
      "0.9914\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.compat.v1.Session() as sess:\n",
    "    sess.run(vars_initializer)\n",
    "    for i in range(steps):\n",
    "        batch_x,batch_y = mnist.train.next_batch(50)\n",
    "        sess.run(cnn_trainer, feed_dict={x: batch_x, y_true: batch_y, hold_prob:0.5})\n",
    "        if i%100 == 0:\n",
    "            print('ON STEP :{}'.format(i))\n",
    "            print('ACCURACY: ')\n",
    "            \n",
    "            matches = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true,1))\n",
    "            acc = tf.reduce_mean(tf.cast(matches, tf.float32))\n",
    "            test_accuracy = sess.run ( acc, feed_dict = {x:mnist.test.images, \\\n",
    "                                                         y_true: mnist.test.labels, \\\n",
    "                                                         hold_prob: 1.0} )\n",
    "            print(test_accuracy)\n",
    "            print('\\n')\n",
    "     \n",
    "     \n",
    "                                                         \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffbf526",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf-cpu.1-15.m100",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf-cpu.1-15:m100"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
